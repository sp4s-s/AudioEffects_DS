{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5650a483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 files\n",
      "Labels saved to labels.json\n",
      "Labels saved to labels.csv\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as n\n",
    "import random\n",
    "import soundfile as sf\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "\n",
    "def pitchify(y, sr, n_steps=None):\n",
    "    if n_steps is None:\n",
    "        n_steps = n.random.uniform(-3, 3)\n",
    "    return librosa.effects.pitch_shift(y=y, sr=sr, n_steps= n_steps)\n",
    "\n",
    "def stretch_time(y, rate=None):\n",
    "    if rate is None:\n",
    "        rate = n.random.uniform(0.4, 2.5)\n",
    "    return librosa.effects.time_stretch(y=y, rate=rate)\n",
    "\n",
    "def add_noise(y, noise_factor=None):\n",
    "    if noise_factor is None:\n",
    "        noise_factor = n.random.uniform(0.001, 0.01)\n",
    "    noise_data = n.random.randn(len(y))\n",
    "    return y + noise_factor * noise_data\n",
    "\n",
    "def split(y, sr, min_duration=3, max_duration=10, n_chunks=5):\n",
    "    chunks = []\n",
    "    out = {}\n",
    "    for i in range(n_chunks):\n",
    "        max_samples = sr * max_duration\n",
    "        start = n.random.randint(0, len(y) - max_samples) if len(y) - max_samples > 0 else 0\n",
    "        chunk_duration = n.random.randint(sr * min_duration, sr * max_duration)\n",
    "        end = min(start + chunk_duration, len(y))\n",
    "        chunks.append(y[start:end])\n",
    "        out[i] = (start, end)\n",
    "    return chunks, out\n",
    "\n",
    "def save_chunks(y_chunks, sr, base_name, path='chunks/'):\n",
    "    chunk_paths = {}\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    for i, chunk in enumerate(y_chunks):\n",
    "        filename = f'{base_name}_chunk_{i}.wav'\n",
    "        full_path = Path(path) / filename\n",
    "        sf.write(full_path, chunk, sr)\n",
    "        chunk_paths[i] = str(full_path)\n",
    "    return chunk_paths\n",
    "\n",
    "def apply_effects(y, effects, base_name, sr=44100, path='chunks/'):\n",
    "    file_names = []\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    for i, effect in enumerate(effects):\n",
    "        y_mod = y.copy()\n",
    "        if effect == \"pitchify\":\n",
    "            y_mod = pitchify(y_mod, sr)\n",
    "        elif effect == \"time_stretch\":\n",
    "            y_mod = stretch_time(y_mod)\n",
    "        elif effect == \"noise\":\n",
    "            y_mod = add_noise(y_mod)\n",
    "        else:\n",
    "            continue\n",
    "        filename = f\"{base_name}_{effect}_{i}.wav\"\n",
    "        full_path = Path(path) / filename\n",
    "        sf.write(full_path, y_mod, sr)\n",
    "        file_names.append(str(full_path))\n",
    "    return file_names\n",
    "\n",
    "def ds_create(path: Path, output_json='labels.json', output_csv='labels.csv'):\n",
    "    files = list(chain(path.glob('*.wav'), path.glob('*.mp3'), path.glob('*.flac')))\n",
    "    if not files:\n",
    "        print(\"No files found\")\n",
    "        return\n",
    "    print(f\"Found {len(files)} files\")\n",
    "    label = {}\n",
    "    for idx, file in enumerate(files):\n",
    "        available_effects = [\"pitchify\", \"time_stretch\", \"noise\"]\n",
    "        n_effects = n.random.randint(1, 4)\n",
    "        chosen_effects = list(n.random.choice(available_effects, n_effects, replace=False))\n",
    "        y, sr = librosa.load(file, sr=None)\n",
    "        chunks, time_stamps = split(y, sr, min_duration=3, max_duration=10, n_chunks=5)\n",
    "        chunk_paths = []\n",
    "        effect_file_outputs = []\n",
    "        for i, (chunk, ts) in enumerate(zip(chunks, time_stamps.values())):\n",
    "            chunk_base = f\"{file.stem}_chunk{i}\"\n",
    "            chunk_out_path = save_chunks([chunk], sr, chunk_base)\n",
    "            chunk_effect_files = apply_effects(chunk, chosen_effects, chunk_base, sr)\n",
    "            chunk_paths.append(chunk_out_path)\n",
    "            effect_file_outputs.append(chunk_effect_files)\n",
    "        label[str(file)] = {\n",
    "            \"Index\": idx,\n",
    "            \"File\": str(file),\n",
    "            \"Effects Applied\": chosen_effects,\n",
    "            \"Chunk Time Stamps (samples)\": time_stamps,\n",
    "            \"Chunk Paths\": chunk_paths,\n",
    "            \"Effect File Outputs\": effect_file_outputs,\n",
    "        }\n",
    "    with open(output_json, 'w') as jf:\n",
    "        json.dump(label, jf, indent=4)\n",
    "    print(f\"Labels saved to {output_json}\")\n",
    "    with open(output_csv, 'w', newline='') as cf:\n",
    "        writer = csv.writer(cf)\n",
    "        writer.writerow([\"Index\", \"File\", \"Effects Applied\", \"Chunk Time Stamps (samples)\", \"Chunk Paths\", \"Effect File Outputs\"])\n",
    "        for data in label.values():\n",
    "            writer.writerow([\n",
    "                data[\"Index\"],\n",
    "                data[\"File\"],\n",
    "                '|'.join(data[\"Effects Applied\"]),\n",
    "                str(data[\"Chunk Time Stamps (samples)\"]),\n",
    "                str(data[\"Chunk Paths\"]),\n",
    "                str(data[\"Effect File Outputs\"])\n",
    "            ])\n",
    "    print(f\"Labels saved to {output_csv}\")\n",
    "\n",
    "ds_create(Path(\"ds/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c486e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 files\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pitch_shift() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mds_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mds/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mds_create\u001b[39m\u001b[34m(path, output_json, output_csv)\u001b[39m\n\u001b[32m     93\u001b[39m chunk_base = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile.stem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_chunk\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     94\u001b[39m chunk_out_path = save_chunks([chunk], sr, chunk_base)  \u001b[38;5;66;03m# only one chunk at a time\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m chunk_effect_files = \u001b[43mapply_effects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m chunk_paths.append(chunk_out_path)\n\u001b[32m     97\u001b[39m effect_file_outputs.append(chunk_effect_files)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mapply_effects\u001b[39m\u001b[34m(y, effects, base_name, sr, path)\u001b[39m\n\u001b[32m     52\u001b[39m y_mod = y.copy()\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m effect == \u001b[33m\"\u001b[39m\u001b[33mpitchify\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     y_mod = \u001b[43mpitchify\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_mod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m effect == \u001b[33m\"\u001b[39m\u001b[33mtime_stretch\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     56\u001b[39m     y_mod = time_stretch(y_mod)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mpitchify\u001b[39m\u001b[34m(y, sr, n_steps)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     15\u001b[39m     n_steps = n.random.uniform(-\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlb\u001b[49m\u001b[43m.\u001b[49m\u001b[43meffects\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpitch_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: pitch_shift() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "ds_create(Path(\"ds/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e13849c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mchunks\u001b[m\u001b[m/      \u001b[34mcodes\u001b[m\u001b[m/       \u001b[34mds\u001b[m\u001b[m/          yfile.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31bea913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/librosa/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "print(librosa.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a9bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1447ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70008786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621c276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07605820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
